%\documentclass{article}

\documentclass[review,onefignum,onetabnum]{siamart190516}

%Packages
\usepackage[utf8]{inputenc}
\usepackage{geometry, graphicx,wrapfig}
\usepackage{enumerate}
%\usepackage{amsmath,amssymb,amsfonts,amsthm, bm}
\usepackage{amsmath,amssymb,amsfonts,bm}
\usepackage{xcolor} %just for visible comments.
\usepackage[linesnumbered,ruled,vlined,algo2e]{algorithm2e}
\usepackage[toc,page]{appendix}
\usepackage{makecell}
\usepackage{cleveref}

% New theorems and commands
%\newtheorem{theorem}{Theorem}[section]
%\newtheorem{lemma}[theorem]{Lemma}
%\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{assump}[theorem]{Assumption}
\newcommand\mycommfont[1]{\ttfamily\textcolor{orange}{#1}}
%\SetCommentSty{mycommfont}
\newcommand{\R}{\mathbb{R}}
\newcommand{\F}{\mathbb{F}}
\newcommand{\dd}{\delta}
\newcommand{\tth}{\theta}
\newcommand{\bb}[1]{\mathbf{#1}}
\newcommand{\fl}{\mathrm{fl}}
\newcommand{\cO}{\mathcal{O}}

\newcommand\blfootnote[1]{%
	\begingroup
	\renewcommand\thefootnote{}\footnote{#1}%
	\addtocounter{footnote}{-1}%
	\endgroup
}

\crefname{algocf}{alg.}{algs.}
\Crefname{algocf}{Algorithm}{Algorithms}
%\theoremstyle{definition}
%\newtheorem{definition}{Definition}[section]
% Document
\title{Rounding Error Analysis of Mixed Precision Block Householder QR Algorithms}
\author{L. Minah Yang, Alyson Fox, and Geoffrey Sanders}
\date{\today}
\begin{document}

\maketitle
\begin{abstract}
	Although mixed precision arithmetic has recently garnered interest for training dense neural networks, many other applications could benefit from the  speed-ups and lower storage if applied appropriately. 
	The growing interest in employing mixed precision computations motivates the need for rounding error analysis that properly handles behavior from mixed precision arithmetic.
	We present a framework for mixed precision analysis that builds on the foundations of rounding error analysis presented in \cite{Higham2002} and demonstrate its practicality by applying the analysis to various Householder QR Algorithms. 
	%In addition, we present successful results from using mixed precision QR factorization for some small-scale benchmark problems in graph clustering. 
	\blfootnote{This work was performed under the auspices of the U.S. Department of Energy by Lawrence Livermore National Laboratory under Contract DE-AC52-07NA27344 and was supported by the LLNL-LDRD Program under Project No. 17-SI-004, LLNL-JRNL-795525-DRAFT.}
\end{abstract}
%TODO: remove graph stuff.
\section{Introduction}\label{sec:intro}
\input{intro2}
\section{Background: Build up to rounding error analysis for inner products}\label{sec:background}
\input{background}
\section{Algorithms and existing round-off error analyses}\label{sec:algo}
\input{algo}
\section{Mixed precision error analysis}\label{sec:mpanalysis}
\input{mpanalysis}
\section{Numerical Experiments}\label{sec:NE}

%Can see first submitted draft by uncommenting below. 
%\input{intro}
%\input{roundingerr}
%\input{HQR}
%\input{TSQR}
%\input{applications}

\section{Conclusion}
Though the use of lower precision naturally reduces the bandwidth and storage needs, the development of GPUs to optimize low precision floating point arithmetic have accelerated the interest in half precision and mixed precision algorithms. 
%the interest in half precision and mixed precision algorithms that demonstrate speedier times, lower energy consumption, and lower memory usage. 
Loss in precision, stability, and representable range offset for those advantages, but these shortcomings may have little to no impact in some applications.
It may even be possible to navigate around those drawbacks with algorithmic design. \par 

The existing rounding error analysis cannot accurately bound the behavior of mixed precision arithmetic.
We have developed a new framework for mixed precision rounding error analysis and applied it to HQR, a widely used linear algebra routine, and implemented it in an iterative eigensolver in the context of spectral clustering. 
The mixed precision error analysis builds from the inner product routine, which can be applied to many other linear algebra tools as well.
The new error bounds more accurately describe how rounding errors are accumulated in mixed precision settings.
We also found that TSQR, a communication-avoiding, easily parallelizable QR factorization algorithm for tall-and-skinny matrices, can outperform HQR in mixed precision settings for ill-conditioned, extremely overdetermined cases, which suggests that some algorithms are more robust against lower precision arithmetic.
%As QR factorizations of tall-and-skinny matrices are common in spectral clustering, we experimented with introducing mixed precision settings into graph partitioning problems.
%In particular, we applied DBSCAN to the spectral basis of a graph identified via subspace iteration that used our simulated mixed precision HQR, which yielded clustering results tantamount to results from employing double-precision entirely.\par

Although this work is focused on QR factorizations and applications in spectral clustering, the mixed precision round-off error analysis can be applied to other tasks and applications that can benefit from employing low precision computations. 
While the emergence of technology that support low precision floats combats issues dealing with storage, now we need to consider how low precision affects stability of numerical algorithms. 
%TODO: Talk about stability?

Future work is needed to test larger, more ill-conditioned problems with different mixed precision settings, and to explore other divide-and-conquer methods like TSQR that can harness parallel capabilities of GPUs while withstanding lower precisions. 

%\appendix
%\input{BQRdeets}
%\input{appendixMPD}
\bibliography{../../../../../library.bib,../../../../../sans_library.bib,./report.bib}
\bibliographystyle{siamplain}%ieeetr
\end{document}
